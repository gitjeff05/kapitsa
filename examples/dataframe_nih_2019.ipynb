{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook goes through the pandas API using some practical examples. It is by no means exhaustive.\n",
    "\n",
    "# Motivation\n",
    "\n",
    "Searching old code and online documentation for how previous problems were solved is time consuming. Keeping a living document and tagging cells with keywords can help bring about solutions faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Raise on chained assignment](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-view-versus-copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "raise",
      "error",
      "chained",
      "assignment"
     ]
    },
    "tags": [
     "raise",
     "chained",
     "mutate"
    ]
   },
   "outputs": [],
   "source": [
    "# notebooks should begin with this so we do not accidentally mutate the original dataframe\n",
    "pd.set_option('mode.chained_assignment','raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, lets read in the data with `read_csv`:\n",
    "\n",
    "NIH data for 2019 was imported from [exporter.nih.gov](https://exporter.nih.gov/ExPORTER_Catalog.aspx?sid=5&index=0). An [explanation of the fields](https://exporter.nih.gov/about.aspx) is helpful for analysis. We took a random sample of 15k rows so this demo could be lightweight.\n",
    "\n",
    "- Explicitly pass `header=0` to be able to replace existing column names.\n",
    "- pass `dtype={ 'ORG_ZIPCODE': 'str'}` to prevent this column from being inferred as an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "read_csv",
      "csv",
      "dates",
      "gzip"
     ]
    },
    "tags": [
     "read_csv",
     "csv",
     "dates",
     "import",
     "dataframe",
     "pandas"
    ]
   },
   "outputs": [],
   "source": [
    "column_names=[\"ID\",\"ACTIVITY\",\"IC\",\"ORG_CITY\",\"ORG_COUNTRY\",\"ORG_DEPT\",\"ORG_NAME\",\"ORG_STATE\",\"ORG_ZIPCODE\",\"PROJECT_START\",\"PROJECT_END\",\"PROJECT_TITLE\",\"DIRECT_COST_AMT\",\"TOTAL_COST\"]\n",
    "df = pd.read_csv('./nih_2019.gzip', header=0, names=column_names, parse_dates=[\"PROJECT_START\",\"PROJECT_END\"], compression='gzip', dtype={ 'ORG_ZIPCODE': 'str'}, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets say we only want to examine US awards.\n",
    "\n",
    "Always use **`copy()`** whenever you assign a **variable to a slice** of your dataframe **when that slice could be used for anything other than just reading**. This way we will avoid any embarrassing [warnings/exceptions regarding setting view on copy](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "setting",
      "view",
      "copy"
     ]
    },
    "tags": [
     "copy",
     "loc",
     "pandas",
     "boolean"
    ]
   },
   "outputs": [],
   "source": [
    "# Always use `copy()` whenever you assign a variable to a slice of your dataframe when that slice could be used for anything other than just reading.\n",
    "us = df.loc[df['ORG_COUNTRY'] == 'UNITED STATES'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now those zip codes are going to be used later to lookup latitude/longitude. Make sure they contain only digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "loc",
      "str",
      "contains",
      "regex"
     ]
    },
    "tags": [
     "pandas",
     "str",
     "contains",
     "regex"
    ]
   },
   "outputs": [],
   "source": [
    "# Find rows that contain any non-digit in column\n",
    "not_okay_zips = us.loc[us['ORG_ZIPCODE'].str.contains('\\D', regex=True), ['ID', 'ORG_CITY', 'ORG_NAME', 'ORG_STATE', 'ORG_ZIPCODE', 'TOTAL_COST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "apply",
      "style",
      "function"
     ]
    },
    "tags": [
     "items",
     "iteration",
     "series"
    ]
   },
   "outputs": [],
   "source": [
    "def highlight_columns(val, match_strings_list):\n",
    "    v = 'background-color: %s; font-weight: %s;' % ('#ff677d', 'bold')\n",
    "    t = 'font-weight: normal'\n",
    "    if (val.name in match_strings_list):\n",
    "        return [v for i in val.items()]\n",
    "    else:\n",
    "        return [t for i in val.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sometimes highlighting a column is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "style",
      "applymap",
      "loc"
     ]
    },
    "tags": [
     "style",
     "apply",
     "pandas"
    ]
   },
   "outputs": [],
   "source": [
    "# highlight a column by using style.apply and passing a function\n",
    "not_okay_zips.head().style.apply(highlight_columns, match_strings_list=['ORG_ZIPCODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oh no, `20,707,359,` does not look like a valid zip code.\n",
    "\n",
    "## Since we just have one baddie, lets correct it using `.loc` -- passing a boolean array and a single column label, `ORG_ZIPCODE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "loc",
      "set"
     ]
    },
    "tags": [
     "dataframe",
     "set"
    ]
   },
   "outputs": [],
   "source": [
    "us.loc[us['ID'] == 10055828, 'ORG_ZIPCODE'] = '20707' # Would have got SettingWithCopyError if we did not use `copy()` above when assigning a slice of `df` to `us`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whew, better. \n",
    "\n",
    "## Wait, what about length? Zip codes should only be 5 or 9 characters. It's probably fine, but lets just check really quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "boolean",
      "index",
      "str",
      "len"
     ]
    },
    "tags": [
     "str",
     "dataframe",
     "pandas",
     "style",
     "apply"
    ]
   },
   "outputs": [],
   "source": [
    "us.loc[~(us['ORG_ZIPCODE'].str.len() == 5) & ~(us['ORG_ZIPCODE'].str.len() == 9)].head().style.apply(highlight_columns, match_strings_list=['ORG_ZIPCODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yikes, that cannot be right. Fret not, we will smote and vanish these dragons!\n",
    "\n",
    "## Looks like the data came with leading zeros pre-stripped from the `ORG_ZIPCODE` column. That is going to make joining a little harder so lets go ahead and fix these.\n",
    "\n",
    "# Pad the zips with `len() < 5` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "items",
      "for",
      "rjust",
      "loc",
      "pad"
     ]
    }
   },
   "outputs": [],
   "source": [
    "is_len_less_five = us['ORG_ZIPCODE'].str.len() < 5\n",
    "us.loc[is_len_less_five, 'ORG_ZIPCODE'] = [s.rjust(5, '0')[:5] for idx, s in us.loc[is_len_less_five, 'ORG_ZIPCODE'].items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad the zips with `len() > 5` next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "items",
      "for",
      "rjust",
      "loc",
      "pad"
     ]
    },
    "tags": [
     "rjust"
    ]
   },
   "outputs": [],
   "source": [
    "is_len_gt_five = us['ORG_ZIPCODE'].str.len() > 5\n",
    "us.loc[(is_len_gt_five), 'ORG_ZIPCODE'] = [s.rjust(9, '0')[:5] for idx, s in us.loc[(is_len_gt_five), 'ORG_ZIPCODE'].items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see if those dragons are gone?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us.loc[~((us['ORG_ZIPCODE'].str.len() == 5) | (us['ORG_ZIPCODE'].str.len() == 9))].size == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import ZIP to GEO data\n",
    "\n",
    "The zip/geo data was [downloaded from ODS](https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/export/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLXppcC1jb2RlLWxhdGl0dWRlLWFuZC1sb25naXR1ZGUiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJBVkciLCJ5QXhpcyI6ImxhdGl0dWRlIiwic2NpZW50aWZpY0Rpc3BsYXkiOnRydWUsImNvbG9yIjoiI0ZGNTE1QSJ9XSwieEF4aXMiOiJzdGF0ZSIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIifV0sInRpbWVzY2FsZSI6IiIsImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWV9&location=3,43.19717,-48.51562&basemap=jawg.streets) (Open Data Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "csv",
      "read_csv"
     ]
    },
    "tags": [
     "dtype",
     "read_csv"
    ]
   },
   "outputs": [],
   "source": [
    "zips_to_coords = pd.read_csv('./zip_geo.gzip', sep=';', compression='gzip', dtype={'Zip': 'str'}, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets make sure there are no dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "duplicated"
     ]
    },
    "tags": [
     "duplicated"
    ]
   },
   "outputs": [],
   "source": [
    "zips_to_coords[zips_to_coords.duplicated('Zip')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait, there are some coordinates missing. We need to append to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "append",
      "ignore_index"
     ]
    },
    "tags": [
     "append",
     "dataframe"
    ]
   },
   "outputs": [],
   "source": [
    "# append an array of series to a dataframe\n",
    "zip_cols = zips_to_coords.columns\n",
    "zips_to_add = [pd.Series(['94158', 37.77244949, -122.39166260], index=zip_cols),\n",
    "               pd.Series(['10065', 40.76429569, -73.96246150], index=zip_cols)]\n",
    "zips_to_coords = zips_to_coords.append(zips_to_add, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_to_coords[zips_to_coords.duplicated('Zip', keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oh I was wrong, those did not need to be added. Lets remove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "drop",
      "duplicates"
     ]
    },
    "tags": [
     "drop_duplicates",
     "pandas",
     "dataframe"
    ]
   },
   "outputs": [],
   "source": [
    "# drop duplicates in place\n",
    "zips_to_coords.drop_duplicates(subset=\"Zip\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_to_coords[zips_to_coords.duplicated('Zip', keep='first')].size == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whew. That was glorious. Now lets merge these dataframes so we can get lat/long on our `us` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "join"
     ]
    },
    "tags": [
     "join",
     "dataframe",
     "pandas"
    ]
   },
   "outputs": [],
   "source": [
    "# join two dataframes on the original dataframes' column. Index must be set appropriately on second df.\n",
    "us = us.join(zips_to_coords.loc[:, ['Zip', 'Latitude', 'Longitude']].set_index('Zip'), on='ORG_ZIPCODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "iloc",
      "style",
      "apply"
     ]
    },
    "tags": [
     "style",
     "apply",
     "pandas"
    ]
   },
   "outputs": [],
   "source": [
    "us.iloc[:5, [0,14,15]].style.apply(highlight_columns, match_strings_list=['Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kapitsa": {
     "pandas": [
      "iloc",
      "style",
      "apply"
     ]
    }
   },
   "source": [
    "## Lets examine top administering agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us['IC'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets say we are only interested in 3 NIH agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_agencies = [{\n",
    "    \"code\": \"AI\",\n",
    "    \"name\": \"NIH National Institute of Allergy and Infectious Diseases (NIAID)\"\n",
    "  }, {\n",
    "    \"code\": \"GM\",\n",
    "    \"name\": \"NIH National Institute of General Medical Sciences (NIGMS)\"\n",
    "  }, {\n",
    "    \"code\": \"CA\",\n",
    "    \"name\": \"NIH National Cancer Institute (NCI)\"\n",
    "  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list = [obj['code'] for obj in nih_agencies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `agc` which contains only grants from AI, GM, CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "agc = us.loc[us['IC'].isin(agency_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc.loc[:, 'TOTAL_COST'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many grant awards have no associated cost information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc.loc[pd.isna(agc['DIRECT_COST_AMT']) & pd.isna(agc['TOTAL_COST'])].style.apply(highlight_columns, match_strings_list=['DIRECT_COST_AMT', 'TOTAL_COST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "groupby",
      "count",
      "index",
      "astype"
     ]
    }
   },
   "outputs": [],
   "source": [
    "# Get a series and count the values grouped by year when column is datetime64[ns]\n",
    "project_start = agc.loc[:, \"PROJECT_START\"].groupby(agc.loc[:, \"PROJECT_START\"].dt.year).count()\n",
    "ps_series = pd.Series(project_start.values, project_start.index.astype('int64'), name=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_end = agc.loc[:, \"PROJECT_END\"].groupby(agc.loc[:, \"PROJECT_END\"].dt.year).count()\n",
    "pe_series = pd.Series(project_end.values, project_end.index.astype('int64'), name=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "matplotlib": [
      "style",
      "use"
     ]
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kapitsa": {
     "pandas": [
      "dataframe",
      "plot",
      "series"
     ]
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from array of series and plot\n",
    "pd.DataFrame([ps_series, pe_series]).T.plot(kind=\"bar\", width=1.0, figsize=(18, 4), title=\"Project Start and End Count by Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc[['TOTAL_COST', 'DIRECT_COST_AMT']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_awards = agc.loc[:, [\"ID\", \"IC\", \"ORG_CITY\", \"ORG_NAME\", \"PROJECT_TITLE\", \"TOTAL_COST\"]].sort_values(by=['TOTAL_COST'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_awards.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What organizations receive the most awards?\n",
    "\n",
    "### Create a series with `value_counts()` that sorts the organizations by award count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_organizations = agc['ORG_NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_organizations[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
